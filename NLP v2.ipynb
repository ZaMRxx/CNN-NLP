{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "file_path = \"C:/kuliah/semester 4/KAL/combined_sentiment_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df['sentence'] = df['sentence'].apply(clean_text)\n",
    "df['sentiment'] = df['sentiment'].map({'negative': 0, 'positive': 1})\n",
    "\n",
    "\n",
    "max_features = 20000  \n",
    "maxlen = 300  \n",
    "tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['sentence'])\n",
    "\n",
    "x = tokenizer.texts_to_sequences(df['sentence'])\n",
    "x = pad_sequences(x, maxlen=maxlen)\n",
    "y = df['sentiment'].values\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Membangun Model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(max_features, 128),\n",
    "    layers.Conv1D(64, kernel_size=5, activation='relu'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Bidirectional(layers.LSTM(128, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)),\n",
    "    layers.Bidirectional(layers.LSTM(64, dropout=0.3, recurrent_dropout=0.3)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 4s/step - accuracy: 0.5089 - loss: 0.6938 - val_accuracy: 0.4955 - val_loss: 0.6929\n",
      "Epoch 2/7\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 4s/step - accuracy: 0.5294 - loss: 0.6913 - val_accuracy: 0.5921 - val_loss: 0.6830\n",
      "Epoch 3/7\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 4s/step - accuracy: 0.7362 - loss: 0.6112 - val_accuracy: 0.7749 - val_loss: 0.4806\n",
      "Epoch 4/7\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 4s/step - accuracy: 0.8974 - loss: 0.2857 - val_accuracy: 0.8006 - val_loss: 0.5009\n",
      "Epoch 5/7\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9598 - loss: 0.1518 - val_accuracy: 0.8172 - val_loss: 0.5622\n",
      "Epoch 6/7\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1s/step - accuracy: 0.9785 - loss: 0.0895 - val_accuracy: 0.8187 - val_loss: 0.6611\n",
      "Epoch 7/7\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - accuracy: 0.9896 - loss: 0.0432 - val_accuracy: 0.8202 - val_loss: 0.6772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1906ac132f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=7, batch_size=64, validation_data=(x_test, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 3s - 150ms/step - accuracy: 0.8202 - loss: 0.6772\n",
      "Akurasi Sentimen Model: 0.8202\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Akurasi Sentimen Model: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Prediksi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    text = clean_text(text)\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(seq, maxlen=maxlen)\n",
    "    prediction = model.predict(padded)[0][0]\n",
    "    sentiment = \"positive\" if prediction > 0.5 else \"negative\"\n",
    "    print(f\"Prediksi Sentimen: {sentiment} ({prediction:.4f})\")\n",
    "\n",
    "\n",
    "text_box = widgets.Text(placeholder=\"Masukkan teks...\")\n",
    "button = widgets.Button(description=\"Prediksi\")\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    text = text_box.value\n",
    "    predict_sentiment(text)\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "display(text_box, button)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
